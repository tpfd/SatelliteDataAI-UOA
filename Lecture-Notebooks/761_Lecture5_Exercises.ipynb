{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zsQKjDt-9yzi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing Deep Learning on Satellite Data\n",
        "\n",
        "Learning goals:\n",
        "- See how a convolutional neural network (CNN) can be trained on small image patches from Sentinel-2.\n",
        "- Understand the difference between using “tabular pixel samples + Random Forest” (what you’ve done already) versus “image patches + CNN” (deep learning).\n"
      ],
      "metadata": {
        "id": "oYBUSAl4668g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________\n",
        "# Exercise: Deep Learning on Satellite Data (Cropland vs Non-Cropland)\n",
        "\n",
        "In order to save time in class I have pre-prepped the patches to train from for you. The code used to do this given at the end of the notebook so that you can use it to generate your own patches in the future.\n",
        "\n",
        "In this exercise, you will use the Sentinel-2 image patches to train a simple deep learning model that can distinguish between cropland and non-cropland.\n",
        "\n",
        "We will go through five stages:\n",
        "\n",
        "      1.) Loading the patch dataset\n",
        "\n",
        "      2.) Preprocessing the data\n",
        "\n",
        "      3.) Building a simple Convolutional Neural Network (CNN)\n",
        "\n",
        "      4.) Training the model\n",
        "\n",
        "      5.) Evaluating the model\n",
        "\n",
        "At the end, you will reflect on what you have learned and think about possible improvements."
      ],
      "metadata": {
        "id": "BtR1LY1A7czn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "!pip install tensorflow matplotlib --quiet\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "VxbaaXiF9VqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load pre-generated dataset\n",
        "The .npz file is available via the class GitHub or Canvas.\n",
        "\n",
        "The patches have already been extracted from a median cloud-free Sentinel-2 composite. Each patch is a small image (64 × 64 × 3 pixels) with a label:\n",
        "- 1 = cropland\n",
        "- 0 = non-cropland\n",
        "\n",
        "Upload the patches ('mount' them into our Colab drive) by just dragging and dropping the .npz file into the 'Files' tab. This is the same tab that you uploaded the .zip file in a prior lab."
      ],
      "metadata": {
        "id": "V1WFiCZl9cPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV4LGX3T6naJ"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = np.load(\"patches.npz\")\n",
        "X, y = data[\"X\"], data[\"y\"]\n",
        "\n",
        "print(\"Patch dataset loaded\")\n",
        "print(\"X shape:\", X.shape)  # (num_patches, 64, 64, 3)\n",
        "print(\"y shape:\", y.shape)  # (num_patches,)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, X contains the image data and y contains the binary labels."
      ],
      "metadata": {
        "id": "OpoF2_TsIJL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Preprocess the data\n",
        "\n",
        "Machine learning models train best when the inputs are normalized (scaled to a common range). Sentinel-2 reflectance values can be large, so we will rescale them to approximately [0, 1]. Notice that we are not normalizing patch-by-patch (which can distort values and remove contrast), but rather scaling consistently across the whole dataset.\n",
        "\n",
        "We also split the data into training and testing sets. The training set is used to fit the model, while the test set evaluates how well the model generalizes to new data."
      ],
      "metadata": {
        "id": "oOSsUkYkGfmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to float32\n",
        "X = X.astype(\"float32\")\n",
        "\n",
        "# Find the global maximum value across ALL patches\n",
        "global_max = X.max()\n",
        "print(\"Global max reflectance across dataset:\", global_max)\n",
        "\n",
        "# Scale all patches by this global max\n",
        "X /= global_max\n",
        "\n",
        "print(\"Scaled X range:\", X.min(), X.max())\n",
        "\n",
        "# Optional: check shapes\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
        "# Optional: double-check shape\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "MUaKKAn9Gld2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Build a simple CNN classifier\n",
        "\n",
        "We’ll use a basic Convolutional Neural Network (CNN) with a few layers to classify patches.\n",
        "\n",
        "A CNN is the standard type of neural network for image classification.\n",
        "It works by applying small filters (convolutions) that detect local features such as edges, textures, and patterns, and then combining these features to make a classification.\n",
        "\n",
        "Here we build a very small CNN:\n",
        "- Two convolutional + pooling layers (feature extraction). More these in future lectures.\n",
        "- A dense hidden layer (decision making)\n",
        "- An output layer with a single unit and sigmoid activation (binary classification)"
      ],
      "metadata": {
        "id": "ocfr8ArgGtch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(64, 64, 3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")  # binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xLfDWYnsGxYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Train the model\n",
        "\n",
        "Now we can train the model using our training data. During training, the model will repeatedly adjust its internal parameters to minimize the classification error.\n",
        "\n",
        "We will train for 10 epochs (iterations over the whole training dataset), using small batches of 8 patches at a time.\n",
        "\n",
        "You should see the training accuracy improve over time."
      ],
      "metadata": {
        "id": "16hvAa9kG9hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=8\n",
        ")\n"
      ],
      "metadata": {
        "id": "O4heHjFWG_Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Evaluate the model\n",
        "\n",
        "Finally, let’s check how well the model performed on unseen test data, and also visualize the training history."
      ],
      "metadata": {
        "id": "HlgqYmD5HEtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "Exw8XcijHG-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's take a look at our patches and sense check that we have indeed classified them correctly."
      ],
      "metadata": {
        "id": "xHwyd0UhLqAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_classified_patches(X, y_true, y_pred, n=12):\n",
        "    \"\"\"\n",
        "    Display patches in a grid with their predicted class.\n",
        "\n",
        "    Args:\n",
        "        X (np.array): Image patches, shape (N, H, W, C).\n",
        "        y_true (np.array): Ground truth labels.\n",
        "        y_pred (np.array): Predicted labels.\n",
        "        n (int): Number of patches to display.\n",
        "    \"\"\"\n",
        "    # Pick the first n patches (or all if fewer exist)\n",
        "    n = min(n, X.shape[0])\n",
        "    cols = 4\n",
        "    rows = int(np.ceil(n / cols))\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(12, rows * 3))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(n):\n",
        "        axes[i].imshow(X[i])\n",
        "        true_label = \"Cropland\" if y_true[i] == 1 else \"Non-cropland\"\n",
        "        pred_label = \"Cropland\" if y_pred[i] == 1 else \"Non-cropland\"\n",
        "        axes[i].set_title(f\"Pred: {pred_label}\\nTrue: {true_label}\", fontsize=9)\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for j in range(i+1, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
        "show_classified_patches(X_test, y_test, y_pred, n=12)"
      ],
      "metadata": {
        "id": "j1Hf8eeyLwOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmmm some good some bad there! But overall not a bad effort given how little training data we have."
      ],
      "metadata": {
        "id": "gxCruYnvMV7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions\n",
        "\n",
        "1. What is the final test accuracy of your model?\n",
        "\n",
        "2. How do the training and validation accuracy curves compare?\n",
        "\n",
        "3. Do you see signs of overfitting (training >> validation)?\n",
        "\n",
        "4. If you had more patches, how might this affect the model performance?\n",
        "\n",
        "5. What are some ways we could improve this experiment? Think about the answer to Q4 here in particular..."
      ],
      "metadata": {
        "id": "5MP7ktpFHN1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________\n",
        "\n",
        "# Patch prep code\n",
        "Here is the code that I used to generate the patches. This is not required for the exercise, but could be useful in future labs and in your project."
      ],
      "metadata": {
        "id": "zsQKjDt-9yzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The usual prep\n",
        "!pip install geemap --quiet\n",
        "\n",
        "import geemap\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='earthengine-ml-testing') #<- Remember to change this to your own project's name!"
      ],
      "metadata": {
        "id": "Az4bZUrBwVUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prep our S2 image usng what we learned in Lab 3\n",
        "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
        "    # Import and filter S2 SR.\n",
        "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date)\n",
        "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
        "\n",
        "    # Import and filter s2cloudless.\n",
        "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date))\n",
        "\n",
        "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
        "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
        "        'primary': s2_sr_col,\n",
        "        'secondary': s2_cloudless_col,\n",
        "        'condition': ee.Filter.equals(**{\n",
        "            'leftField': 'system:index',\n",
        "            'rightField': 'system:index'\n",
        "        })\n",
        "    }))\n",
        "\n",
        "\n",
        "def add_cloud_bands(img):\n",
        "    # Get s2cloudless image, subset the probability band.\n",
        "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "\n",
        "    # Condition s2cloudless by the probability threshold value.\n",
        "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
        "\n",
        "    # Add the cloud probability layer and cloud mask as image bands.\n",
        "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
        "\n",
        "\n",
        "def add_shadow_bands(img):\n",
        "    # Identify water pixels from the SCL band.\n",
        "    not_water = img.select('SCL').neq(6)\n",
        "\n",
        "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
        "    SR_BAND_SCALE = 1e4\n",
        "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
        "\n",
        "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
        "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
        "\n",
        "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
        "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
        "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
        "        .select('distance')\n",
        "        .mask()\n",
        "        .rename('cloud_transform'))\n",
        "\n",
        "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
        "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
        "\n",
        "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
        "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
        "\n",
        "\n",
        "def add_cld_shdw_mask(img):\n",
        "    # Add cloud component bands.\n",
        "    img_cloud = add_cloud_bands(img)\n",
        "\n",
        "    # Add cloud shadow component bands.\n",
        "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
        "\n",
        "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
        "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
        "\n",
        "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
        "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
        "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
        "        .rename('cloudmask'))\n",
        "\n",
        "    # Add the final cloud-shadow mask to the image.\n",
        "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
        "\n",
        "\n",
        "# Define a function to apply the cloud mask to the S2 spectral bands\n",
        "def apply_cld_shdw_mask(img):\n",
        "    cloudmask = img.select('cloudmask')\n",
        "    # Mask cloudy pixels\n",
        "    masked_img = img.updateMask(cloudmask.Not())\n",
        "    # Keep cloudmask and probability bands\n",
        "    cloudmask_band = img.select('cloudmask')\n",
        "    probability_band = img.select('probability')\n",
        "    masked_img = masked_img.addBands([cloudmask_band, probability_band], overwrite=True)\n",
        "    return masked_img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Controls ----------\n",
        "AOI = ee.Geometry.Point(174.7633, -36.8485)\n",
        "START_DATE = '2023-01-01'\n",
        "END_DATE = '2023-03-31'\n",
        "CLOUD_FILTER = 60\n",
        "CLD_PRB_THRESH = 50\n",
        "NIR_DRK_THRESH = 0.15\n",
        "CLD_PRJ_DIST = 1\n",
        "BUFFER = 50\n",
        "\n",
        "# --------- Generate stack ------\n",
        "# Get the collection\n",
        "s2_sr_cld_col = get_s2_sr_cld_col(AOI, START_DATE, END_DATE)\n",
        "\n",
        "# Process the collection\n",
        "s2_sr_median = (s2_sr_cld_col.map(add_cld_shdw_mask)\n",
        "                             .map(apply_cld_shdw_mask)\n",
        "                             .median())"
      ],
      "metadata": {
        "id": "MKHpWY6xvcGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patch(image, point, size=64, scale=10):\n",
        "    region = point.buffer(size * scale / 2).bounds()\n",
        "    patch = geemap.ee_to_numpy(\n",
        "        image,\n",
        "        region=region,\n",
        "        bands=['B4', 'B3', 'B2'],\n",
        "        scale=scale\n",
        "    )\n",
        "    if patch is None:\n",
        "        return None\n",
        "\n",
        "    # Force consistent patch size (size, size, 3)\n",
        "    h, w, c = patch.shape\n",
        "    target = (size, size, c)\n",
        "    patch_fixed = np.zeros(target, dtype=patch.dtype)\n",
        "\n",
        "    h_min = min(h, size)\n",
        "    w_min = min(w, size)\n",
        "    patch_fixed[:h_min, :w_min, :] = patch[:h_min, :w_min, :]\n",
        "\n",
        "    return np.clip(patch_fixed / 3000, 0, 1)\n",
        "\n",
        "def save_patches(image, cropland_pts, non_cropland_pts, outfile=\"patches.npz\", size=64, scale=10):\n",
        "    X_list, y_list, coords = [], [], []\n",
        "\n",
        "    # Cropland first (label=1)\n",
        "    for pt in cropland_pts:\n",
        "        p = extract_patch(image, pt, size=size, scale=scale)\n",
        "        if p is not None:\n",
        "            X_list.append(p)\n",
        "            y_list.append(1)\n",
        "            coords.append(pt.coordinates().getInfo())  # [lon, lat]\n",
        "\n",
        "    # Non-cropland (label=0)\n",
        "    for pt in non_cropland_pts:\n",
        "        p = extract_patch(image, pt, size=size, scale=scale)\n",
        "        if p is not None:\n",
        "            X_list.append(p)\n",
        "            y_list.append(0)\n",
        "            coords.append(pt.coordinates().getInfo())  # [lon, lat]\n",
        "\n",
        "    if len(X_list) == 0:\n",
        "        raise RuntimeError(\"No patches extracted.\")\n",
        "\n",
        "    X = np.stack(X_list, axis=0)\n",
        "    y = np.array(y_list, dtype=int)\n",
        "    coords = np.array(coords, dtype=float)  # shape (N,2) [lon,lat]\n",
        "\n",
        "    np.savez_compressed(outfile, X=X, y=y, coords=coords)\n",
        "\n",
        "    print(f\"Saved {X.shape[0]} patches to {os.path.abspath(outfile)}\")\n",
        "    print(f\"  Cropland patches (y==1): {(y==1).sum()}\")\n",
        "    print(f\"  Non-cropland patches (y==0): {(y==0).sum()}\")\n",
        "    print(f\"  Patch shape: {X.shape[1:]}\")\n",
        "    return X, y, coords\n",
        "\n",
        "\n",
        "def show_patches(X, y, coords=None, n=3):\n",
        "    cropland_idx = np.where(y == 1)[0]\n",
        "    non_idx = np.where(y == 0)[0]\n",
        "\n",
        "    n = min(n, len(cropland_idx), len(non_idx))\n",
        "    if n == 0:\n",
        "        print(\"No patches to display.\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(2, n, figsize=(5*n, 8))\n",
        "    if n == 1:\n",
        "        axes = np.array([[axes[0]], [axes[1]]])  # normalize shape\n",
        "\n",
        "    # Top row: cropland\n",
        "    for i in range(n):\n",
        "        idx = cropland_idx[i]\n",
        "        axes[0, i].imshow(X[idx])\n",
        "        if coords is not None:\n",
        "            lon, lat = coords[idx]\n",
        "            axes[0, i].set_title(f\"Cropland (1)\\n{lat:.4f}, {lon:.4f}\")\n",
        "        else:\n",
        "            axes[0, i].set_title(\"Cropland (1)\")\n",
        "        axes[0, i].axis(\"off\")\n",
        "\n",
        "    # Bottom row: non-cropland\n",
        "    for i in range(n):\n",
        "        idx = non_idx[i]\n",
        "        axes[1, i].imshow(X[idx])\n",
        "        if coords is not None:\n",
        "            lon, lat = coords[idx]\n",
        "            axes[1, i].set_title(f\"Non-crop (0)\\n{lat:.4f}, {lon:.4f}\")\n",
        "        else:\n",
        "            axes[1, i].set_title(\"Non-crop (0)\")\n",
        "        axes[1, i].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zfIju1yij1m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define example points\n",
        "cropland_points = [\n",
        "    ee.Geometry.Point([174.952922, -37.024492]),\n",
        "    ee.Geometry.Point([174.554596, -36.788981]),\n",
        "    ee.Geometry.Point([174.936961, -37.032787]),\n",
        "    ee.Geometry.Point([174.551965, -36.807036]),\n",
        "    ee.Geometry.Point([174.556182, -36.801054]),\n",
        "    ee.Geometry.Point([174.567911, -36.808468])\n",
        "]\n",
        "non_cropland_points = [\n",
        "    ee.Geometry.Point([174.821293, -36.916761]),\n",
        "    ee.Geometry.Point([174.879206, -36.919512]),\n",
        "    ee.Geometry.Point([174.942332, -37.055910]),\n",
        "    ee.Geometry.Point([174.940074, -37.065542]),\n",
        "    ee.Geometry.Point([174.543226, -36.770280]),\n",
        "    ee.Geometry.Point([174.910122, -37.038162])\n",
        "]\n",
        "\n",
        "# Run\n",
        "X, y, coords = save_patches(s2_sr_median, cropland_points, non_cropland_points, \"patches.npz\")\n",
        "show_patches(X, y, coords, n=6)"
      ],
      "metadata": {
        "id": "lGPPm8xW99JF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}