{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 4: Deep Learning for Satellite Data\n",
        "This notebook uses a pre-made training dataset to develop a simple deep learning classifier for finding solar pannels in Sentinel 2 imagery. The learning objectives for this lab are to:\n",
        "\n",
        "1. Load and use a pre-labeled training dataset (e.g. polygons or patches with land cover classes).\n",
        "2. Prepare that data for use in a deep learning model.\n",
        "3. Train a deep learning model in TensorFlow/Keras using these labels.\n",
        "\n",
        "At the end of the lab you will be asked to reflect on model performance, generalization, and sources of error.\n"
      ],
      "metadata": {
        "id": "yhu_D7hJyqEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etRkmr2KmKsC"
      },
      "outputs": [],
      "source": [
        "# Set up, couple of new libraries here so expect install times to take longer than you have been used to\n",
        "!pip install -q tensorflow rasterio geemap matplotlib scikit-learn tqdm --quiet\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import re\n",
        "import rasterio\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set our random seeds for reproducibility\n",
        "SEED = 42 #<- the meaning of life, this is why you always see people setting seeds to 42 by the way...\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "A-UXlkz38BKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your training data has been downloaded from:\n",
        "\n",
        "*   [Solafune](https://solafune.com/competitions/5dfc315c-1b24-4573-804f-7de8d707cd90?id=&menu=data&topicId=54728653-0e25-4975-baad-6fe2f5185844)\n",
        "\n",
        "Find the data on Canvas or download directly from their website the 'train.zip'. The competition that this dataset was created for is now over, but that is good for us as it means you can look at the winning solutions for inspiration!\n",
        "\n",
        "If you want to download the data yourself you will need to sign up for an account and then 'enter' the competition. You can do this all without charge but it does require and email address sign up.\n",
        "\n",
        "We are just going to use the 'train.zip' data and split that into our train and test, in order to sligthly reduce the burden on our notebooks. Remember that ultimately we would want to validate it, and you will see that the data source actually has a completely seperate store of images for that purpose.\n",
        "\n",
        "Take that .zip file and get it into your g-drive/local space as per usual practice. Leave it zipped.\n"
      ],
      "metadata": {
        "id": "WAKL3TAJ1yVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume train.zip is already uploaded to Colab file store, extract it\n",
        "zip_path = \"/content/train.zip\"\n",
        "extract_dir = Path(\"/content/train_data\")\n",
        "extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "  z.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "HucYCi6g1vDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our data extracted, we now need to build lists of each sample patch and the labelled mask of it, connecting the two. I have written this relatively robustly (e.g. you can set it to handle different file extensions and it checks that it is finding the correct files), so that hopefully you can use it more widely than just in this lab."
      ],
      "metadata": {
        "id": "hvY9rN2Z7tw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the file extenion we are using\n",
        "f_ex = \"*.tif\"\n",
        "\n",
        "# Locate directories\n",
        "s2_dir = next((p for p in extract_dir.rglob('*') if p.is_dir() and 's2_image' in p.name.lower()), None)\n",
        "mask_dir = next((p for p in extract_dir.rglob('*') if p.is_dir() and 'mask' in p.name.lower()), None)\n",
        "\n",
        "assert s2_dir and mask_dir, \"Could not locate s2_image/ and mask/ directories.\"\n",
        "print(\"Found Sentinel-2 image dir:\", s2_dir)\n",
        "print(\"Found mask dir:\", mask_dir)\n",
        "\n",
        "# Match files to each other from each sub-directory by trailing numeric ID\n",
        "s2_files = {re.search(r'_(\\d+)\\.tif$', f.name).group(1): f for f in Path(s2_dir).glob(f_ex)}\n",
        "mask_files = {re.search(r'_(\\d+)\\.tif$', f.name).group(1): f for f in Path(mask_dir).glob(f_ex)}\n",
        "\n",
        "# Build pairs of images and masks\n",
        "common_ids = sorted(set(s2_files.keys()) & set(mask_files.keys()))\n",
        "assert len(common_ids) > 0, \"No paired s2_image/mask files found with matching IDs.\"\n",
        "\n",
        "pairs = []\n",
        "for i in common_ids:\n",
        "    s2_path, mask_path = s2_files[i], mask_files[i]\n",
        "    with rasterio.open(s2_path) as s2, rasterio.open(mask_path) as m:\n",
        "        assert (s2.height, s2.width) == (m.height, m.width), \\\n",
        "            f\"Shape mismatch: {s2_path.name} vs {mask_path.name}\"\n",
        "    pairs.append((s2_path, mask_path))\n",
        "\n",
        "print(f\"Found {len(pairs)} valid paired samples.\")\n",
        "print(\"Example pair:\", pairs[0])"
      ],
      "metadata": {
        "id": "cG8V43A37tan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick sanity check: visualize one random pair out of the first 31 available\n",
        "# Run this cell a few times to check that you have different files and that the mask looks about right\n",
        "pair_num = np.random.randint(0,30)\n",
        "s2_path, mask_path = pairs[pair_num]\n",
        "\n",
        "with rasterio.open(s2_path) as src:\n",
        "    s2_img = src.read([3,2,1])  # RGB bands for Sentinel-2 (B4, B3, B2)\n",
        "    s2_img = np.transpose(s2_img, (1,2,0))\n",
        "    s2_img = (s2_img - s2_img.min()) / (s2_img.max() - s2_img.min())\n",
        "\n",
        "with rasterio.open(mask_path) as src:\n",
        "    mask = src.read(1)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(s2_img)\n",
        "plt.title(\"Sentinel-2 RGB Patch\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(mask, cmap=\"gray\")\n",
        "plt.title(\"Mask\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hzij3jXU-SNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up we are going to prepare out training data into numpy arrays that are then able to be passed into TensorFlow. However, if we try to hold all 2000+ patches in RAM whilst we do, the Colab instance will crash. If on your own laptop, it will also die unless you have spent a lot more money than I have on mine. Furthermore, even if we had a HPC level of RAM available it is a good idea to do things in a 'memory safe' manner that means we can scale our training with more samples if we so deisred it.\n",
        "\n",
        "The safe pattern is therefore to:\n",
        "1. Load a batch of patches.\n",
        "2. Normalize/resize them.\n",
        "3. Save them to disk (e.g. as .npy, .npz, or TFRecords/HDF5).\n",
        "4. Free memory and move on.\n",
        "5. Then later, when training, you stream batches directly from disk.\n",
        "\n",
        "Here’s a disk-based pipeline with batching using numpy.savez_compressed (safe + easy to reload):"
      ],
      "metadata": {
        "id": "ldr_zbvV_L8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_or_pad(arr, target_h, target_w):\n",
        "    h, w = arr.shape[:2]\n",
        "    c = arr.shape[2] if arr.ndim == 3 else 1\n",
        "\n",
        "    arr = cv2.resize(\n",
        "        arr,\n",
        "        (target_w, target_h),\n",
        "        interpolation=cv2.INTER_NEAREST if c == 1 else cv2.INTER_LINEAR)\n",
        "\n",
        "    if arr.ndim == 2:\n",
        "        arr = arr[..., np.newaxis]\n",
        "    return arr\n",
        "\n",
        "\n",
        "# Set storage folder\n",
        "OUTPUT_DIR = \"patch_store\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_HEIGHT, TARGET_WIDTH = 256, 256\n",
        "BATCH_SIZE = 100  # tune based on memory available\n",
        "\n",
        "\n",
        "X_batch, Y_batch = [], []\n",
        "batch_idx = 0\n",
        "\n",
        "for i, (s2_path, mask_path) in enumerate(tqdm(pairs, desc=\"Processing\")):\n",
        "    # Load Sentinel-2\n",
        "    with rasterio.open(s2_path) as src:\n",
        "        img = src.read().astype(np.float32)  # (bands, H, W)\n",
        "        img = np.transpose(img, (1, 2, 0))  # (H, W, bands)\n",
        "\n",
        "    # Load mask\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        mask = src.read(1).astype(np.uint8)\n",
        "\n",
        "    # Resize/pad\n",
        "    img = resize_or_pad(img, TARGET_HEIGHT, TARGET_WIDTH)\n",
        "    mask = resize_or_pad(mask, TARGET_HEIGHT, TARGET_WIDTH)\n",
        "\n",
        "    # Normalize\n",
        "    img = img / 10000.0\n",
        "\n",
        "    # Add to batch\n",
        "    X_batch.append(img)\n",
        "    Y_batch.append(mask)\n",
        "\n",
        "    # Save batch to disk when full\n",
        "    if len(X_batch) >= BATCH_SIZE:\n",
        "        X_batch = np.stack(X_batch)\n",
        "        Y_batch = np.stack(Y_batch)\n",
        "\n",
        "        np.savez_compressed(\n",
        "            os.path.join(OUTPUT_DIR, f\"batch_{batch_idx:04d}.npz\"),\n",
        "            X=X_batch, Y=Y_batch\n",
        "        )\n",
        "\n",
        "        # Reset\n",
        "        batch_idx += 1\n",
        "        X_batch, Y_batch = [], []\n",
        "\n",
        "# Save any leftovers\n",
        "if len(X_batch) > 0:\n",
        "    X_batch = np.stack(X_batch)\n",
        "    Y_batch = np.stack(Y_batch)\n",
        "    np.savez_compressed(\n",
        "        os.path.join(OUTPUT_DIR, f\"batch_{batch_idx:04d}.npz\"),\n",
        "        X=X_batch, Y=Y_batch\n",
        "    )\n",
        "\n",
        "# By the way it is the 'tqdm' element that is providing the nifty progress bar. I always like to include it when waiting for things so that I know it is actually running.\n",
        "\n",
        "# This block might take five to ten minutes to run as we are doing this in a linear manner (rather than parallell processing).\n",
        "# An optimised version of thise code is to pass each batch to a seperate CPU thread/core."
      ],
      "metadata": {
        "id": "bf8AmhFm_N0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-10 minutes later... (mine took 8 minutes and 32 seconds), we can now move on. Because we are not storing our training data in our RAM like we did in the lecture exercise, we have to load it in as we want it."
      ],
      "metadata": {
        "id": "RSRtw0_ddyfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First up, set a bunch of parameters that we can modify in order to save our RAM load. In short, the lower these values the less RAM you will use but the worse the results:"
      ],
      "metadata": {
        "id": "k5kavUyxfWEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramater for RAM saving\n",
        "TARGET_HEIGHT, TARGET_WIDTH = 128, 128  # smaller patch -> saves RAM & compute\n",
        "BANDS = 3  # RGB only -> reduces memory\n",
        "BATCH_SIZE = 4  # small batch -> reduces RAM usage\n",
        "MAX_TRAIN_FILES = 5  # only use subset for lab demonstration\n",
        "MAX_VAL_FILES = 2"
      ],
      "metadata": {
        "id": "Jgz5V8ZdwcP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**: We have used three bands here. What is the total numnber of bands we could make available to the CNN if we so chose?"
      ],
      "metadata": {
        "id": "MK9MDZr43tai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we find our patch files:"
      ],
      "metadata": {
        "id": "VkWpwojiwhbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Locate the batched .npz files\n",
        "all_files = sorted(glob.glob(\"patch_store/*.npz\"))\n",
        "np.random.shuffle(all_files)\n",
        "\n",
        "train_files = all_files[:MAX_TRAIN_FILES]\n",
        "val_files   = all_files[-MAX_VAL_FILES:]"
      ],
      "metadata": {
        "id": "IfHUhDLDwjKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**: What is the total number of patches in our training data and the total number in our validation set? (With the parameters set as I have done in the notebook).\n",
        "\n",
        "Tip: you can either programmatically count what is in train_files/val_files, or you can calculate it from the parameters that have been set across the cells above this one."
      ],
      "metadata": {
        "id": "xz6GToVO4gTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then we need to change our masks to a binary label. If we were doing segmenation we would keep it as a the mask, but in this case we are just trying to find patches that contain solar pannels rather than the specific solar pannel outline."
      ],
      "metadata": {
        "id": "5VQet50zx6xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask to binary label\n",
        "def mask_to_label(mask_batch):\n",
        "    \"\"\"1 if any solar pixel in mask, else 0\"\"\"\n",
        "    labels = (np.sum(mask_batch, axis=(1,2,3)) > 0).astype(np.float32)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "plCwY8IYyGLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need a tool to load our data in from the batched files:"
      ],
      "metadata": {
        "id": "uQARTP5zyQEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loader\n",
        "def npz_loader_cls(path):\n",
        "    \"\"\"Load one .npz batch, downsample patches, convert to RGB, convert mask to label\"\"\"\n",
        "    data = np.load(path.numpy().decode(\"utf-8\"))\n",
        "    X = data[\"X\"]\n",
        "    Y_mask = data[\"Y\"]\n",
        "\n",
        "    # RAM saving: pick first 3 bands only\n",
        "    X = X[..., :BANDS]\n",
        "\n",
        "    # RAM saving: downsample patches\n",
        "    from skimage.transform import resize\n",
        "    X_resized = np.zeros((X.shape[0], TARGET_HEIGHT, TARGET_WIDTH, BANDS), dtype=np.float32)\n",
        "    for i in range(X.shape[0]):\n",
        "        X_resized[i] = resize(X[i], (TARGET_HEIGHT, TARGET_WIDTH, BANDS), anti_aliasing=True)\n",
        "\n",
        "    X = X_resized\n",
        "\n",
        "    Y = mask_to_label(Y_mask)\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "eH48IPpVehJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now define our training and validation datasets, which will only be actually populated with data as required, rather than loading it all into memory at once."
      ],
      "metadata": {
        "id": "IHjVNIO9gScU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow dataset pipeline\n",
        "def tf_wrapper(path):\n",
        "    X, Y = tf.py_function(npz_loader_cls, [path], [tf.float32, tf.float32])\n",
        "    X.set_shape([None, TARGET_HEIGHT, TARGET_WIDTH, BANDS])\n",
        "    Y.set_shape([None])\n",
        "    # Flatten file-batch into individual samples\n",
        "    return tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "\n",
        "def make_cls_dataset(file_list, batch_size=BATCH_SIZE, shuffle=True, repeat=True):\n",
        "    files = tf.data.Dataset.from_tensor_slices(file_list)\n",
        "    if shuffle:\n",
        "        files = files.shuffle(len(file_list))\n",
        "\n",
        "    # RAM saving: stream samples via interleave\n",
        "    ds = files.interleave(\n",
        "        lambda f: tf_wrapper(f),\n",
        "        cycle_length=4,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(2048)\n",
        "\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    if repeat:\n",
        "        ds = ds.repeat()\n",
        "\n",
        "    return ds\n",
        "\n",
        "train_ds = make_cls_dataset(train_files, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_ds   = make_cls_dataset(val_files, batch_size=BATCH_SIZE, shuffle=False, repeat=False)"
      ],
      "metadata": {
        "id": "-dHkpClEgPp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**: Are we shuffling the training dataset? Are we shuffling the validation dataset?"
      ],
      "metadata": {
        "id": "ExxsU7IL5n7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to specify our model settings. We are just using a simple CNN here, the same sort as we used the lecture exercise. But, this time it has signficantly more layers and therefore parameters (but far less than you might use for your project). It may take a few minutes to set up:"
      ],
      "metadata": {
        "id": "ZhBQrzrJhKZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple CNN\n",
        "# We are determining the input shape from one batch\n",
        "for X_sample, _ in train_ds.take(1):\n",
        "    input_shape = X_sample.shape[1:]  # (H, W, bands)\n",
        "    break\n",
        "\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "y9YqcO1BhIP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4**: Which type of activation funding is our final layer using and why are we using this function as our final layer?"
      ],
      "metadata": {
        "id": "m8lBb_Mk553F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the model ready to train, we have one more preperation step to make. We need to count the total samples available in this particular run. This is because you can change the number of samples via the RAM paramaters earlier, and therefore we should assume in this code a static number of samples will always be available when setting our number of steps per epoch."
      ],
      "metadata": {
        "id": "AABBOTGhy4AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total samples\n",
        "def count_samples(files):\n",
        "    total = 0\n",
        "    for f in files:\n",
        "        total += np.load(f)[\"X\"].shape[0]\n",
        "    return total\n",
        "\n",
        "n_train = count_samples(train_files)\n",
        "n_val   = count_samples(val_files)\n",
        "\n",
        "steps_per_epoch = max(1, n_train // BATCH_SIZE)\n",
        "validation_steps = max(1, n_val // BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ckagcnDHy8l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we train the model! It should take 5-10 minutes to run on a free-user Colab notebook."
      ],
      "metadata": {
        "id": "qpg6jT_Zh3af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This 'callbacks' set of instructions is a handy way to avoid wasting time\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",          # Watch the validation loss\n",
        "        patience=3,                  # If it doesn't improve for 3 epochs, stop training\n",
        "        restore_best_weights=True    # Roll back to the best-performing weights\n",
        "    )\n",
        "]\n",
        "\n",
        "# Run the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=5,  # small number for lab demonstration\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "SyHO0Uf9gcC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizie the predictions:"
      ],
      "metadata": {
        "id": "fYyznO5nilZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training curves\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label=\"train\")\n",
        "plt.plot(history.history['val_loss'], label=\"val\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label=\"train\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RGOz-632imi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_patch_predictions_grid(dataset, model, n_rows=2, n_cols=5):\n",
        "    \"\"\"\n",
        "    Display predictions in a grid: n_rows x n_cols\n",
        "    Includes histogram stretch for better visualization of RGB patches.\n",
        "    \"\"\"\n",
        "    def stretch(img):\n",
        "        \"\"\"Contrast stretch to 0–1 for display.\"\"\"\n",
        "        img = img.astype(np.float32)\n",
        "        p2, p98 = np.percentile(img, (2, 98))\n",
        "        img = np.clip((img - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "        return img\n",
        "\n",
        "    for X, Y_true in dataset.take(1):\n",
        "        # live classification of the patch using the trained model\n",
        "        Y_pred = model.predict(X, verbose=0)\n",
        "        n_total = min(n_rows * n_cols, X.shape[0])\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i in range(n_total):\n",
        "            rgb = X[i, :, :, :3].numpy()\n",
        "            rgb = stretch(rgb)  # apply histogram stretch\n",
        "            axes[i].imshow(rgb)\n",
        "            axes[i].set_title(f\"T:{int(Y_true[i].numpy())}\\nP:{Y_pred[i,0]:.2f}\")\n",
        "            axes[i].axis(\"off\")\n",
        "\n",
        "        # hide any unused axes\n",
        "        for i in range(n_total, len(axes)):\n",
        "            axes[i].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example\n",
        "show_patch_predictions_grid(val_ds, model, n_rows=1, n_cols=5)"
      ],
      "metadata": {
        "id": "KIKyqZr31CGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remembering that this is a effectively still a toy CNN with tiny data, we can see that we have built a model that gives us a probability of the patches containing a solar pannel. We know that for all of the patchs used in this training, the answer is true..."
      ],
      "metadata": {
        "id": "iyreuxmU1hcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5**: Is this a robust and reliable model for the detection of solar panels in a new Sentinel 2 image that has never been seen by the model before? Explain your answer with reference to the design of the training data, the settings of the CNN and the performance statistics seen."
      ],
      "metadata": {
        "id": "KhBj404z12H7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6**: Exercise: using the materials taught in Lab 3 and given your answer to Q5, re-design your training data so that it is a robust training set for the detection of solar panels in S2 data. Your answer needs to include:\n",
        "*   A paragraph that explains what you have added to the train_data and any other steps taken in order to enhance the robustness of the training.\n",
        "*   A figure that demonstrates your newly added patches vs. the existing patches (remember that it needs to be publication quality).\n",
        "\n",
        "You do not need to create a 100% solution here. I am looking for you to demonstrate an understanding of the critical design flaw in this training set (particularly for a patch based, as opposed to segmentation approach), and to show critical thinking in how you might fix it. This may include re-samnping the existing training data, including new training data or changing the bands being used (or all of the above).\n",
        "\n"
      ],
      "metadata": {
        "id": "yIpojp9o_hof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7**: Exercise: re-run the model with your new training data (remembering that I am not looking for a total solution), and further adjusted hyperparameters/RAM options. Write two paragraphs that:\n",
        "1. Sets out **all the changes** you have made and the reasoning for them.\n",
        "2. Asses the training and model results in terms of performance statistics, commenting on how/if your training data changes have made an impact.\n",
        "\n",
        "You may include figures to support your analysis if you wish, remembering to present them to publication standard if you do so."
      ],
      "metadata": {
        "id": "TpmT0KuvAphE"
      }
    }
  ]
}